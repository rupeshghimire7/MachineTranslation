{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1067156,"sourceType":"datasetVersion","datasetId":592212}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Machine Translation\n\n**English-to-French**\n\nHELLO WORLD = BONJOUR LE MONDE","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence  # pad batch\nimport spacy  # for tokenizer\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T04:26:04.458084Z","iopub.execute_input":"2024-04-18T04:26:04.458782Z","iopub.status.idle":"2024-04-18T04:26:04.463663Z","shell.execute_reply.started":"2024-04-18T04:26:04.458749Z","shell.execute_reply":"2024-04-18T04:26:04.462772Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# from torchtext.vocab import build_vocab_from_iterator\n# from torchtext.datasets import Multi30k","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:43:02.687276Z","iopub.execute_input":"2024-04-18T03:43:02.687649Z","iopub.status.idle":"2024-04-18T03:43:02.691628Z","shell.execute_reply.started":"2024-04-18T03:43:02.687625Z","shell.execute_reply":"2024-04-18T03:43:02.690679Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download fr_core_news_sm\n\nspacy_en = spacy.load('en_core_web_sm')\nspacy_fr = spacy.load('fr_core_news_sm')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:43:20.712206Z","iopub.execute_input":"2024-04-18T03:43:20.712569Z","iopub.status.idle":"2024-04-18T03:43:47.270505Z","shell.execute_reply.started":"2024-04-18T03:43:20.712543Z","shell.execute_reply":"2024-04-18T03:43:47.269623Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting fr-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from fr-core-news-sm==3.7.0) (3.7.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.3)\nInstalling collected packages: fr-core-news-sm\nSuccessfully installed fr-core-news-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('fr_core_news_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/language-translation-englishfrench/eng_-french.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:43:47.272099Z","iopub.execute_input":"2024-04-18T03:43:47.272401Z","iopub.status.idle":"2024-04-18T03:43:48.680177Z","shell.execute_reply.started":"2024-04-18T03:43:47.272375Z","shell.execute_reply":"2024-04-18T03:43:48.679320Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  English words/sentences French words/sentences\n0                     Hi.                 Salut!\n1                    Run!                Cours !\n2                    Run!               Courez !\n3                    Who?                  Qui ?\n4                    Wow!             Ça alors !","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Perform Basic Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"import string","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:43:48.681375Z","iopub.execute_input":"2024-04-18T03:43:48.681678Z","iopub.status.idle":"2024-04-18T03:43:48.687919Z","shell.execute_reply.started":"2024-04-18T03:43:48.681653Z","shell.execute_reply":"2024-04-18T03:43:48.687070Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.columns = ['english', 'french']\n\ndef preprocess_text(text):\n    text = text.lower()  # Convert text to lowercase\n    text = ''.join(char for char in text if char not in string.punctuation)  # Remove punctuation\n    return text\n\ndf['en'] = df['english'].apply(lambda x: preprocess_text(x))\ndf['fr'] = df['french'].apply(lambda x: ''.join(char for char in x if char not in string.punctuation))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:43:48.689734Z","iopub.execute_input":"2024-04-18T03:43:48.690288Z","iopub.status.idle":"2024-04-18T03:43:51.055019Z","shell.execute_reply.started":"2024-04-18T03:43:48.690262Z","shell.execute_reply":"2024-04-18T03:43:51.054052Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:44:06.704125Z","iopub.execute_input":"2024-04-18T03:44:06.704504Z","iopub.status.idle":"2024-04-18T03:44:06.715401Z","shell.execute_reply.started":"2024-04-18T03:44:06.704475Z","shell.execute_reply":"2024-04-18T03:44:06.714530Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  english      french   en         fr\n0     Hi.      Salut!   hi      Salut\n1    Run!     Cours !  run     Cours \n2    Run!    Courez !  run    Courez \n3    Who?       Qui ?  who       Qui \n4    Wow!  Ça alors !  wow  Ça alors ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>french</th>\n      <th>en</th>\n      <th>fr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n      <td>hi</td>\n      <td>Salut</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n      <td>run</td>\n      <td>Cours</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n      <td>run</td>\n      <td>Courez</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n      <td>who</td>\n      <td>Qui</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n      <td>wow</td>\n      <td>Ça alors</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# To build vocabulary out of the text in captions\n\nclass Vocabulary:\n    def __init__(self, freq_threshold, en=True): # store a word in vocab if its occurance is more than the frequency threshold\n        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"} # to store all tokens and map with index as key\n        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3} # map index as value to tokens\n        self.freq_threshold = freq_threshold \n        self.en = en\n\n    def __len__(self):\n        return len(self.itos)\n    \n    def __getitem__(self,idx):\n        return list(self.itos.items())[idx]\n\n    @staticmethod\n    def tokenizer_eng(text):\n        return [tok.text.lower() for tok in spacy_en.tokenizer(text)]\n    \n    @staticmethod\n    def tokenizer_french(text):\n        return [tok.text.lower() for tok in spacy_fr.tokenizer(text)]\n\n    def build_vocabulary(self, sentence_list):\n        frequencies = {} # temp dict to store words \n        idx = 4 # because we have tokens for index 0-3 already assigned\n\n        for sentence in sentence_list:  # caption file as list\n            if self.en==True:\n                tokenizer = self.tokenizer_eng\n            else:\n                tokenizer = self.tokenizer_french\n            for word in tokenizer(sentence): # takes each sentence and returns a token list of that sentence\n                if word not in frequencies:\n                    frequencies[word] = 1    \n\n                else:\n                    frequencies[word] += 1\n\n                if frequencies[word] == self.freq_threshold:\n                    self.stoi[word] = idx  # new word with freq>threshold mapped to index\n                    self.itos[idx] = word  # new word:index mapping\n                    idx += 1\n\n    def numericalize(self, text): # return index for given text/sentence else return index for UNK (unknown)\n        if self.en==True:\n            tokenized_text = self.tokenizer_eng(text)\n        else:\n            tokenized_text = self.tokenizer_french(text)\n        return [\n            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n            for token in tokenized_text\n        ]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:44:09.439683Z","iopub.execute_input":"2024-04-18T03:44:09.440322Z","iopub.status.idle":"2024-04-18T03:44:09.453032Z","shell.execute_reply.started":"2024-04-18T03:44:09.440292Z","shell.execute_reply":"2024-04-18T03:44:09.452118Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# english to french\n\n#english\nsrc_vocab = Vocabulary(2)\nsrc_vocab.build_vocabulary(df['en'])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:44:09.815860Z","iopub.execute_input":"2024-04-18T03:44:09.816760Z","iopub.status.idle":"2024-04-18T03:44:15.518770Z","shell.execute_reply.started":"2024-04-18T03:44:09.816726Z","shell.execute_reply":"2024-04-18T03:44:15.517755Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"len(src_vocab), src_vocab.numericalize(\"I am Running\"), src_vocab[99]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:44:44.824213Z","iopub.execute_input":"2024-04-18T03:44:44.825100Z","iopub.status.idle":"2024-04-18T03:44:44.833626Z","shell.execute_reply.started":"2024-04-18T03:44:44.825067Z","shell.execute_reply":"2024-04-18T03:44:44.832746Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(9953, [10, 74, 762], (99, 'did'))"},"metadata":{}}]},{"cell_type":"code","source":"trg_vocab = Vocabulary(2, en=False)\ntrg_vocab.build_vocabulary(df['fr'])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:45:09.167240Z","iopub.execute_input":"2024-04-18T03:45:09.168071Z","iopub.status.idle":"2024-04-18T03:45:17.194025Z","shell.execute_reply.started":"2024-04-18T03:45:09.168039Z","shell.execute_reply":"2024-04-18T03:45:17.193062Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"len(trg_vocab), trg_vocab.numericalize('bonjour le monde'), trg_vocab[5]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T03:45:19.546814Z","iopub.execute_input":"2024-04-18T03:45:19.547522Z","iopub.status.idle":"2024-04-18T03:45:19.557110Z","shell.execute_reply.started":"2024-04-18T03:45:19.547492Z","shell.execute_reply":"2024-04-18T03:45:19.556183Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(17995, [275, 112, 1059], (5, 'ça'))"},"metadata":{}}]},{"cell_type":"code","source":"class MyDataset(nn.Module):\n    def __init__(self, src_vocab, trg_vocab, df):\n        self.src_vocab = src_vocab\n        self.trg_vocab = trg_vocab\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    \n    def __getitem__(self, idx):\n        english = self.df['en'][idx]\n        french = self.df['fr'][idx]\n        \n        eng_num = [self.src_vocab.stoi['<SOS>']]\n        eng_num += self.src_vocab.numericalize(english)\n        eng_num.append(self.src_vocab.stoi['<EOS>'])\n    \n        fr_num = [self.trg_vocab.stoi['<SOS>']]\n        fr_num += self.trg_vocab.numericalize(french)\n        fr_num.append(self.trg_vocab.stoi['<EOS>'])\n        \n        return torch.tensor(eng_num), torch.tensor(fr_num)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:41.032580Z","iopub.execute_input":"2024-04-18T04:25:41.033202Z","iopub.status.idle":"2024-04-18T04:25:41.041129Z","shell.execute_reply.started":"2024-04-18T04:25:41.033174Z","shell.execute_reply":"2024-04-18T04:25:41.040094Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class MyCollate: \n    def __init__(self, pad_idx):\n        self.pad_idx = pad_idx\n\n    def __call__(self, batch):\n        source = [item[0] for item in batch]\n        source = pad_sequence(source, batch_first=False, padding_value=self.pad_idx)\n        target = [item[1] for item in batch]\n        target = pad_sequence(target, batch_first=False, padding_value=self.pad_idx)\n\n        return source, target","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:42.761073Z","iopub.execute_input":"2024-04-18T04:25:42.761893Z","iopub.status.idle":"2024-04-18T04:25:42.767833Z","shell.execute_reply.started":"2024-04-18T04:25:42.761865Z","shell.execute_reply":"2024-04-18T04:25:42.766808Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def get_loader(\n    src_vocab,\n    trg_vocab,\n    df,\n    batch_size=32,\n#     num_workers=4,\n    shuffle=True,\n    pin_memory=True,\n):\n    dataset = MyDataset(src_vocab, trg_vocab, df)\n    pad_idx = src_vocab.stoi[\"<PAD>\"]\n\n    loader = DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n#         num_workers=num_workers,\n        shuffle=shuffle,\n        pin_memory=pin_memory,\n        collate_fn=MyCollate(pad_idx=pad_idx),\n    )\n\n    return loader, dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:42.985071Z","iopub.execute_input":"2024-04-18T04:25:42.985869Z","iopub.status.idle":"2024-04-18T04:25:42.991262Z","shell.execute_reply.started":"2024-04-18T04:25:42.985840Z","shell.execute_reply":"2024-04-18T04:25:42.990404Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"data_loader, ds = get_loader(src_vocab, trg_vocab, df)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:43.751233Z","iopub.execute_input":"2024-04-18T04:25:43.752226Z","iopub.status.idle":"2024-04-18T04:25:43.756836Z","shell.execute_reply.started":"2024-04-18T04:25:43.752193Z","shell.execute_reply":"2024-04-18T04:25:43.755828Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:44.117347Z","iopub.execute_input":"2024-04-18T04:25:44.117734Z","iopub.status.idle":"2024-04-18T04:25:44.123405Z","shell.execute_reply.started":"2024-04-18T04:25:44.117707Z","shell.execute_reply":"2024-04-18T04:25:44.122528Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"5489"},"metadata":{}}]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n\n        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n        self.dropout = nn.Dropout(p)\n\n    def forward(self, x):\n        # x: (seq_length, N) where N is batch size\n\n        embedding = self.dropout(self.embedding(x))\n        # embedding shape: (seq_length, N, embedding_size)\n\n        encoder_states, (hidden, cell) = self.rnn(embedding)\n        # outputs shape: (seq_length, N, hidden_size)\n\n        # Use forward, backward cells and hidden through a linear layer\n        # so that it can be input to the decoder which is not bidirectional\n        # Also using index slicing ([idx:idx+1]) to keep the dimension\n        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n\n        return encoder_states, hidden, cell\n\n\nclass Decoder(nn.Module):\n    def __init__(\n        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n    ):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n\n        self.energy = nn.Linear(hidden_size * 3, 1)\n        self.fc = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(p)\n        self.softmax = nn.Softmax(dim=0)\n        self.relu = nn.ReLU()\n\n    def forward(self, x, encoder_states, hidden, cell):\n        x = x.unsqueeze(0)\n        # x: (1, N) where N is the batch size\n\n        embedding = self.dropout(self.embedding(x))\n        # embedding shape: (1, N, embedding_size)\n\n        sequence_length = encoder_states.shape[0]\n        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n        # h_reshaped: (seq_length, N, hidden_size*2)\n\n        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n        # energy: (seq_length, N, 1)\n\n        attention = self.softmax(energy)\n        # attention: (seq_length, N, 1)\n\n        # attention: (seq_length, N, 1), snk\n        # encoder_states: (seq_length, N, hidden_size*2), snl\n        # we want context_vector: (1, N, hidden_size*2), i.e knl\n        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n\n        rnn_input = torch.cat((context_vector, embedding), dim=2)\n        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n\n        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n        # outputs shape: (1, N, hidden_size)\n\n        predictions = self.fc(outputs).squeeze(0)\n        # predictions: (N, hidden_size)\n\n        return predictions, hidden, cell\n\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_force_ratio=0.5):\n        batch_size = source.shape[1]\n        target_len = target.shape[0]\n        target_vocab_size = len(trg_vocab)\n\n        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n        encoder_states, hidden, cell = self.encoder(source)\n\n        # First input will be <SOS> token\n        x = target[0]\n\n        for t in range(1, target_len):\n            # At every time step use encoder_states and update hidden, cell\n            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n\n            # Store prediction for current time step\n            outputs[t] = output\n\n            # Get the best word the Decoder predicted (index in the vocabulary)\n            best_guess = output.argmax(1)\n\n            # With probability of teacher_force_ratio we take the actual next word\n            # otherwise we take the word that the Decoder predicted it to be.\n            # Teacher Forcing is used so that the model gets used to seeing\n            # similar inputs at training and testing time, if teacher forcing is 1\n            # then inputs at test time might be completely different than what the\n            # network is used to. This was a long comment.\n            x = target[t] if random.random() < teacher_force_ratio else best_guess\n\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:46.707327Z","iopub.execute_input":"2024-04-18T04:25:46.708022Z","iopub.status.idle":"2024-04-18T04:25:46.729347Z","shell.execute_reply.started":"2024-04-18T04:25:46.707991Z","shell.execute_reply":"2024-04-18T04:25:46.728397Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:47.491035Z","iopub.execute_input":"2024-04-18T04:25:47.491413Z","iopub.status.idle":"2024-04-18T04:25:47.498403Z","shell.execute_reply.started":"2024-04-18T04:25:47.491388Z","shell.execute_reply":"2024-04-18T04:25:47.497420Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"num_epochs = 50\nlearning_rate = 3e-4","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:47.670516Z","iopub.execute_input":"2024-04-18T04:25:47.671379Z","iopub.status.idle":"2024-04-18T04:25:47.675417Z","shell.execute_reply.started":"2024-04-18T04:25:47.671336Z","shell.execute_reply":"2024-04-18T04:25:47.674365Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Model hyperparameters\ninput_size_encoder = len(src_vocab)\ninput_size_decoder = len(trg_vocab)\noutput_size = len(trg_vocab)\nencoder_embedding_size = 300\ndecoder_embedding_size = 300\nhidden_size = 1024\nnum_layers = 1\nenc_dropout = 0.0\ndec_dropout = 0.0","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:47.837736Z","iopub.execute_input":"2024-04-18T04:25:47.838698Z","iopub.status.idle":"2024-04-18T04:25:47.844250Z","shell.execute_reply.started":"2024-04-18T04:25:47.838662Z","shell.execute_reply":"2024-04-18T04:25:47.843187Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"\nencoder_net = Encoder(\n    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\n\ndecoder_net = Decoder(\n    input_size_decoder,\n    decoder_embedding_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    dec_dropout,\n).to(device)\n\nmodel = Seq2Seq(encoder_net, decoder_net).to(device)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\npad_idx = src_vocab.stoi[\"<PAD>\"]\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_idx)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:48.408499Z","iopub.execute_input":"2024-04-18T04:25:48.409170Z","iopub.status.idle":"2024-04-18T04:25:49.028169Z","shell.execute_reply.started":"2024-04-18T04:25:48.409137Z","shell.execute_reply":"2024-04-18T04:25:49.027173Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"sentence = \"Hello World! I winning UCL. HALA MADRID\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:49.029706Z","iopub.execute_input":"2024-04-18T04:25:49.030005Z","iopub.status.idle":"2024-04-18T04:25:49.034052Z","shell.execute_reply.started":"2024-04-18T04:25:49.029981Z","shell.execute_reply":"2024-04-18T04:25:49.033191Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def translate_sentence(model, sentence, device, max_length=50):\n#     # Load french tokenizer\n#     spacy_fr = spacy.load('fr_core_news_sm')\n#     spacy_en = spacy.load('en_core_news_sm')\n    \n#     # Create tokens using spacy and everything in lower case (which is what our vocab is)\n#     if type(sentence) == str:\n#         tokens = [token.text.lower() for token in spacy_en(sentence)]\n#     else:\n#         tokens = [token.lower() for token in sentence]\n    \n    \n    # Add <SOS> and <EOS> in beginning and end respectively\n    en_tokens = [src_vocab.stoi['<SOS>']]\n    en_tokens += src_vocab.numericalize(sentence)\n    en_tokens.append(src_vocab.stoi['<EOS>'])\n\n#     # Go through each german token and convert to an index\n#     text_to_indices = [german.vocab.stoi[token] for token in tokens]\n\n    # Convert to Tensor\n    sentence_tensor = torch.LongTensor(en_tokens).unsqueeze(1).to(device)\n\n    # Build encoder hidden, cell state\n    with torch.no_grad():\n        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n\n    outputs = [trg_vocab.stoi[\"<SOS>\"]]\n\n    for _ in range(max_length):\n        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n\n        with torch.no_grad():\n            output, hiddens, cells = model.decoder(\n                previous_word, outputs_encoder, hiddens, cells\n            )\n            best_guess = output.argmax(1).item()\n\n        outputs.append(best_guess)\n\n        # Model predicts it's the end of the sentence\n        if output.argmax(1).item() == trg_vocab.stoi[\"<EOS>\"]:\n            break\n\n    translated_sentence = [trg_vocab.itos[idx] for idx in outputs]\n\n    # remove start token\n    return translated_sentence[1:]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:25:49.888374Z","iopub.execute_input":"2024-04-18T04:25:49.889280Z","iopub.status.idle":"2024-04-18T04:25:49.897997Z","shell.execute_reply.started":"2024-04-18T04:25:49.889249Z","shell.execute_reply":"2024-04-18T04:25:49.897148Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"[Epoch {epoch} / {num_epochs}]\")\n\n    model.eval()\n\n    translated_sentence = translate_sentence(\n        model, sentence, device, max_length=50\n    )\n\n    print(f\"Translated example sentence: \\n {translated_sentence}\")\n\n    model.train()\n\n    for batch_idx, batch in enumerate(data_loader):\n        # Get input and targets and get to cuda\n        inp_data, target = batch[0].to(device), batch[1].to(device)\n\n        # Forward prop\n        output = model(inp_data, target)\n\n        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n        # doesn't take input in that form. For example if we have MNIST we want to have\n        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n        # way that we have output_words * batch_size that we want to send in into\n        # our cost function, so we need to do some reshapin. While we're at it\n        # Let's also remove the start token while we're at it\n        output = output[1:].reshape(-1, output.shape[2])\n        target = target[1:].reshape(-1)\n\n        optimizer.zero_grad()\n        loss = criterion(output, target)\n\n        # Back prop\n        loss.backward()\n\n        # Clip to avoid exploding gradient issues, makes sure grads are\n        # within a healthy range\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n\n        # Gradient descent step\n        optimizer.step()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T04:26:10.721791Z","iopub.execute_input":"2024-04-18T04:26:10.722468Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[Epoch 0 / 50]\nTranslated example sentence: \n ['devina', 'devina', 'embauchés', 'impatients', 'essaim', 'eaux', 'gueules', 'encaisseront', 'mattendes', 'encaisseront', 'octobre', 'champêtre', 'ravis', 'déroba', 'dansons', 'marchâmes', 'endéans', 'évidences', 'minute', 'négocié', 'détendues', 'tom', 'part', 'laffaire', 'commencement', 'tavons', 'taider', 'seront', 'aiderait', 'mordit', 'ford', 'inacceptable', 'spatiale', '1', 'transporté', 'abstraite', 'renversé', 'habitez', 'habitez', 'fournirent', 'réalistes', 'consciencieusement', 'dieu', 'devrais', 'défense', 'suggéra', 'terrifiée', 'colère', 'vécu', 'reprendre']\n[Epoch 1 / 50]\nTranslated example sentence: \n ['en', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 2 / 50]\nTranslated example sentence: \n ['en', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 3 / 50]\nTranslated example sentence: \n ['le', '<UNK>', 'que', 'je', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 4 / 50]\nTranslated example sentence: \n ['le', '<UNK>', 'que', 'je', '<UNK>', '<UNK>', '<UNK>', 'des', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 5 / 50]\nTranslated example sentence: \n ['le', 'moins', '<UNK>', '<UNK>', '<UNK>', 'des', '<UNK>', 'de', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 6 / 50]\nTranslated example sentence: \n ['le', 'monde', '<UNK>', 'le', 'monde', '<UNK>', 'le', '<UNK>', '<UNK>', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 7 / 50]\nTranslated example sentence: \n ['le', 'monde', '<UNK>', 'à', '<UNK>', 'des', '<UNK>', '<UNK>', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 8 / 50]\nTranslated example sentence: \n ['le', 'monde', '<UNK>', '<UNK>', 'jai', '<UNK>', 'de', '<UNK>', 'des', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 9 / 50]\nTranslated example sentence: \n ['des', '<UNK>', 'de', 'la', 'je', '<UNK>', 'jai', '<UNK>', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 10 / 50]\nTranslated example sentence: \n ['du', 'monde', '<UNK>', 'de', 'monde', 'je', '<UNK>', 'de', '<UNK>', 'les', '<UNK>', '<EOS>']\n[Epoch 11 / 50]\nTranslated example sentence: \n ['des', '<UNK>', 'de', '<UNK>', '<UNK>', 'le', '<UNK>', 'de', '<UNK>', 'les', '<UNK>', 'des', '<UNK>', '<EOS>']\n[Epoch 12 / 50]\nTranslated example sentence: \n ['les', '<UNK>', 'de', '<UNK>', '<UNK>', 'le', '<UNK>', 'de', '<UNK>', '<UNK>', 'des', '<UNK>', '<EOS>']\n[Epoch 13 / 50]\nTranslated example sentence: \n ['les', 'grandes', '<UNK>', 'le', 'monde', '<UNK>', 'le', 'monde', '<UNK>', 'de', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 14 / 50]\nTranslated example sentence: \n ['grâce', 'à', 'ce', 'qui', 'ma', 'poussé', '<UNK>', 'des', '<UNK>', '<UNK>', 'des', '<UNK>', '<EOS>']\n[Epoch 15 / 50]\nTranslated example sentence: \n ['des', '<UNK>', 'de', 'gens', 'je', '<UNK>', 'le', '<UNK>', 'de', '<UNK>', 'des', '<UNK>', '<EOS>']\n[Epoch 16 / 50]\nTranslated example sentence: \n ['les', '<UNK>', '<UNK>', '<UNK>', 'je', '<UNK>', '<UNK>', 'me', '<UNK>', 'des', '<UNK>', '<EOS>']\n[Epoch 17 / 50]\nTranslated example sentence: \n ['salut', 'de', 'monde', 'je', 'passe', 'du', '<UNK>', 'des', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 18 / 50]\nTranslated example sentence: \n ['des', 'films', 'que', 'le', 'monde', 'je', '<UNK>', 'des', '<UNK>', 'de', '<UNK>', 'à', '<UNK>', '<EOS>']\n[Epoch 19 / 50]\nTranslated example sentence: \n ['des', '<UNK>', '<UNK>', 'je', '<UNK>', 'le', 'des', '<UNK>', 'qui', 'ont', 'des', '<UNK>', '<EOS>']\n[Epoch 20 / 50]\nTranslated example sentence: \n ['que', 'que', 'le', 'monde', '<UNK>', 'le', '\\xa0\\xa0', '»', '«', 'des', '<UNK>', '<UNK>', 'de', '<UNK>', '<EOS>']\n[Epoch 21 / 50]\nTranslated example sentence: \n ['salut', 'le', 'monde', 'que', 'je', '<UNK>', 'le', 'monde', '<UNK>', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 22 / 50]\nTranslated example sentence: \n ['bien', 'que', 'le', 'monde', '<UNK>', 'le', 'monde', 'de', '<UNK>', '<UNK>', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 23 / 50]\nTranslated example sentence: \n ['le', 'monde', 'je', '<UNK>', 'des', 'conseils', 'du', 'monde', '<UNK>', '»', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 24 / 50]\nTranslated example sentence: \n ['des', '<UNK>', 'de', 'monde', 'je', 'donne', 'le', 'des', '<UNK>', '<UNK>', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 25 / 50]\nTranslated example sentence: \n ['de', '<UNK>', '<UNK>', 'le', 'monde', '<UNK>', 'des', '<UNK>', '<UNK>', 'qui', 'joue', 'des', '<UNK>', '<UNK>', '<EOS>']\n[Epoch 26 / 50]\nTranslated example sentence: \n ['quand', 'le', 'monde', '<UNK>', 'que', 'je', '<UNK>', 'des', '<UNK>', '<UNK>', 'des', '<UNK>', '<EOS>']\n[Epoch 27 / 50]\nTranslated example sentence: \n ['bien', 'le', 'monde', '<UNK>', 'le', 'monde', '<UNK>', 'les', '<UNK>', '<UNK>', 'le', '<UNK>', '<EOS>']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}